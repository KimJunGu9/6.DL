{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5906767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\jkkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\jkkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from opencv-python) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "518645a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a061915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding='same' : 자동으로 패딩을 삽입해 입력값과 출력값의 크기를 맞춰줌\n",
    "# padding='valid' : 패딩을 적용하지 않고 필터를 적용해서 출력값의 크기가 작아짐\n",
    "\n",
    "def get_sequential_model(input_shape):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(input_shape), # 입력 layer\n",
    "\n",
    "\n",
    "\n",
    "            # 1st\n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu',padding='same'), #CNN모델의 레이어, 64개의 필터, 3by3짜리 필터크기, \n",
    "            layers.Conv2D(64, 3, strides=1, activation='relu',padding='same'), # strides=1은 옆으로 1칸씩 가는 것 \n",
    "            # 두번 가중치를 주면 좀 더 곡선이 살아남\n",
    "            layers.MaxPool2D(), # 연산량을 줄여주면서 그 안에 있는 특징을 추출하기위해 maxpool2d사용\n",
    "            layers.BatchNormalization(), # 값들을 정규화함.(사실 해도되고 안해도됨) \n",
    "                                        # 한 이유는 픽셀값들의 크기를 정리해줘서 속도를 빠르게하기위해\n",
    "            layers.Dropout(0.5), # 과대적합하지않게 50%를 학습시킴(이 것도 해도되고 안해도됨)\n",
    "                                # 나중에 실제로 값을 적용했을때 좋ㅁ 더 좋은 성능을 낼 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "            # 2nd\n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu',padding='same'), #CNN모델의 레이어, 128개의 필터, 3by3짜리 필터크기, \n",
    "            layers.Conv2D(128, 3, strides=1, activation='relu',padding='same'),\n",
    "            # 두번 가중치를 주면 좀 더 곡선이 살아남\n",
    "            layers.MaxPool2D(), # 연산량을 줄여주면서 그 안에 있는 특징을 추출하기위해 maxpool2d사용\n",
    "            layers.BatchNormalization(), # 값들을 정규화.\n",
    "            layers.Dropout(0.3), # 과대적합하지않게 # 30%를 학습시킴        \n",
    "\n",
    "\n",
    "\n",
    "            # 레이어를 두번 사용\n",
    "\n",
    "\n",
    "            # FC\n",
    "            layers.GlobalMaxPool2D(), # 여태까지 왔던 모든 데이터를 maxpool함\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(1, activation='sigmoid'), # 시그모이드로 판단\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "182ad1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model = get_sequential_model(input_shape)\n",
    "\n",
    "model.compile( # compile함수 사용해서 설정값 설정\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bba1ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train',shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.csv_path = csv_path\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self. shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "            \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac = 1).reset_index(drop = True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size # 만약 idx에 0번을 넣으면 0부터 시작, 1번이면 1* self.batch_size이다\n",
    "        end = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[start:end] # 만약 0부터 64미만이라면\n",
    "        batch_x, batch_y = self.get_data(data) # 리턴되는 값이 두개가 나옴\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = [] # self가 안붙었으니 이 batch_x,y는 이 메소드 안에서만 사용한다.\n",
    "        \n",
    "        for _, r in data.iterrows(): # data에서 넘어오는 리스트가 인덱스번호(_)는 안쓰고, 데이터(r)는 쓴다\n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'C:/python/Jupyter/jupyter/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size)) # 이미지 크기가 다 제각각이므로 다 동일하게 맞춤\n",
    "            iamge = image/ 255. # 나눠준 이유는 정규화하기 위해(나중에 cnn모델 쓸때 색상정보는 기울기로 쓰이는데 숫자가 낮아지면 속도가 빨라지니까)\n",
    "            \n",
    "            label = int(r['species']) - 1 # soecies보면 1로 되어있는데 9부터 시작하기위해 -1을 해준다\n",
    "            \n",
    "            batch_x.append(image) # 계속 쌓아줌\n",
    "            batch_y.append(label)\n",
    "            \n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee8a4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'C:/python/Jupyter/jupyter/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 256,\n",
    "    mode = 'train',\n",
    "    shuffle = True    \n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 256,\n",
    "    mode = 'val',\n",
    "    shuffle = True    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21fbce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping: Epoch을 많이 돌린 후 특정 시점에 멈추게 함\n",
    "\n",
    "# monitor: EarlyStopping의 기준이 되는 값. 예) val_loss 더이상 감소되지 않을 경우 EarlyStopping 적용\n",
    "\n",
    "# patience: Training이 진행됨에도 더이상 monitor되는 값의 개선이 없을 경우 몇번 epoch을 진행할 지 설정\n",
    "\n",
    "# mode: monitor되는 값이 최소가 되야 하는지, 최대가 되야 하는지 설정\n",
    "\n",
    "# restore_best_weights: true로 설정하면 training이 끝난 후 model의 wieght를 monitor하고 있던 값이 가장\n",
    "# 좋았을 경우의 weight로 복원. False라면 마지막 training이 끝난 후의 weight로 설정\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, mode='min', restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20692efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau: 모델의 개선이 없을 경우 learning rate를 조절해 모델의 개선을 유도함\n",
    "\n",
    "# monitor: ReduceLROnPlateau의 기준이 되는 값. 예) val_loss 더이상 감소되지 않을 경우 ReduceLROnPlateau 적용\n",
    "\n",
    "# factor: learning rate를 얼마나 변경시킬 것인지 정하는 값. learning rate * factor\n",
    "\n",
    "# patience: training이 진행됨에도 더이상 monitor되는 값의 개선이 없을 경우 최적의 monitor값을 기준으로\n",
    "# 몇 번의 epoch을 진행하고 learning rate를 조절할지의 값을 설정\n",
    "\n",
    "\n",
    "reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=10, mode='min', min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2355593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint: 모델의 경로 설정\n",
    "\n",
    "# 모델 경로를 '{epoch:02d}-{val_loss:.2f}.hdf5' 라고 하면 앞의 명시한 문자열로 파일을 저장\n",
    "# 예) 01-0.12f.h5\n",
    "\n",
    "# save_weights_only: True(weight만 저장), False(모델, layer, weight 모두 저장)\n",
    "\n",
    "# save_best_only: True(모델의 정확도가 최고값을 갱신했을 때만 저장), False(매회 저장)\n",
    "\n",
    "\n",
    "filepath = '{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bed931e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21940\\1353968809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mreduce_on_plateau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     ]\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\jkkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jkkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \"\"\"\n\u001b[1;32m--> 511\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        reduce_on_plateau,\n",
    "        model_checkpoint\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400699b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
